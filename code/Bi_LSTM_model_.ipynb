{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "gNn4pjZmTCkA",
      "metadata": {
        "id": "gNn4pjZmTCkA"
      },
      "source": [
        "# BiLSTM MODEL (Deep Learning Approach)\n",
        "##### Using tokenized Reddit posts + optional GloVe embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FCEaphnpUZIV",
      "metadata": {
        "id": "FCEaphnpUZIV"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TB-7IBCFUx1k",
      "metadata": {
        "id": "TB-7IBCFUx1k"
      },
      "source": [
        "Setup & sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OXM1qpu6KPvA",
      "metadata": {
        "id": "OXM1qpu6KPvA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nLoWhHEMKPsZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLoWhHEMKPsZ",
        "outputId": "0ae77149-c239-4340-979c-10e5fb316bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: train=1980406, val=495102, test=618878\n"
          ]
        }
      ],
      "source": [
        "assert 'X_train' in globals() and 'X_val' in globals() and 'X_test' in globals(), \"Missing X_* splits\"\n",
        "assert 'y_train' in globals() and 'y_val' in globals() and 'y_test' in globals(), \"Missing y_* splits\"\n",
        "\n",
        "# Keepping reproducible\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"Samples: train={len(X_train)}, val={len(X_val)}, test={len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ngh07DMNU-2J",
      "metadata": {
        "id": "ngh07DMNU-2J"
      },
      "source": [
        "Tokenize & pad sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ybo6iMJ-VExj",
      "metadata": {
        "id": "ybo6iMJ-VExj"
      },
      "outputs": [],
      "source": [
        "# Hyperparams\n",
        "MAX_VOCAB   = 30000\n",
        "MAX_LEN     = 200\n",
        "OOV_TOKEN   = \"<OOV>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MADv-tJ6VbgA",
      "metadata": {
        "id": "MADv-tJ6VbgA"
      },
      "outputs": [],
      "source": [
        "# Fitting tokenizer on training text\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=OOV_TOKEN)\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K2f8Mqj0VEvA",
      "metadata": {
        "id": "K2f8Mqj0VEvA"
      },
      "outputs": [],
      "source": [
        "# Converting to integer sequences\n",
        "def to_seq(texts):\n",
        "    return tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "Xtr_seq = to_seq(X_train)\n",
        "Xva_seq = to_seq(X_val)\n",
        "Xte_seq = to_seq(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2hv6fF3tVEsQ",
      "metadata": {
        "id": "2hv6fF3tVEsQ"
      },
      "outputs": [],
      "source": [
        "# Pad to fixed length\n",
        "Xtr_pad = pad_sequences(Xtr_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "Xva_pad = pad_sequences(Xva_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "Xte_pad = pad_sequences(Xte_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "ytr = np.asarray(y_train).astype(int)\n",
        "yva = np.asarray(y_val).astype(int)\n",
        "yte = np.asarray(y_test).astype(int)\n",
        "\n",
        "vocab_size = min(MAX_VOCAB, len(tokenizer.word_index) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M_eaRpuUVEpA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_eaRpuUVEpA",
        "outputId": "3f7ddaa4-df64-4d8b-91c9-016bf2c68978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size used: 30000 | Sequence shape: (1980406, 200)\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocab size used:\", vocab_size, \"| Sequence shape:\", Xtr_pad.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MefhDFFxXLo9",
      "metadata": {
        "id": "MefhDFFxXLo9"
      },
      "outputs": [],
      "source": [
        "import os, zipfile, io, requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WWl0ygKoXOQE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWl0ygKoXOQE",
        "outputId": "e161201c-26d6-43e5-c200-c727927c21e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GloVe embeddings...\n",
            "GloVe downloaded and extracted.\n"
          ]
        }
      ],
      "source": [
        "EMB_DIM = 100\n",
        "MAX_VOCAB   = 30000\n",
        "OOV_TOKEN   = \"<OOV>\"\n",
        "\n",
        "glove_zip_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "glove_dir = \"glove\"\n",
        "glove_zip = os.path.join(glove_dir, \"glove.6B.zip\")\n",
        "glove_txt = os.path.join(glove_dir, f\"glove.6B.{EMB_DIM}d.txt\")\n",
        "\n",
        "os.makedirs(glove_dir, exist_ok=True)\n",
        "\n",
        "def ensure_glove():\n",
        "    if not os.path.exists(glove_txt):\n",
        "        try:\n",
        "            print(\"Downloading GloVe embeddings...\")\n",
        "            r = requests.get(glove_zip_url, timeout=60)\n",
        "            z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "            z.extractall(glove_dir)\n",
        "            print(\"GloVe downloaded and extracted.\")\n",
        "        except Exception as e:\n",
        "            print(\"Could not download GloVe:\", e)\n",
        "\n",
        "ensure_glove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sa5QLv9pIoRV",
      "metadata": {
        "id": "Sa5QLv9pIoRV"
      },
      "outputs": [],
      "source": [
        "# Fitting tokenizer on training text\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=OOV_TOKEN)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "vocab_size = min(MAX_VOCAB, len(tokenizer.word_index) + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sXKd9v2NIoOH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXKd9v2NIoOH",
        "outputId": "89af487a-238a-4447-b6b4-436cec65d3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embeddings from: glove/glove.6B.100d.txt\n",
            "Loaded 26996 / 30000 embeddings.\n"
          ]
        }
      ],
      "source": [
        "# Build embedding matrix\n",
        "embedding_matrix = np.random.normal(0, 0.6, size=(vocab_size, EMB_DIM)).astype(np.float32)\n",
        "found = 0\n",
        "\n",
        "if os.path.exists(glove_txt):\n",
        "    print(\"Loading embeddings from:\", glove_txt)\n",
        "    embeddings_index = {}\n",
        "    with open(glove_txt, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            values = line.rstrip().split(\" \")\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype=\"float32\")\n",
        "            embeddings_index[word] = coefs\n",
        "    for word, idx in tokenizer.word_index.items():\n",
        "        if idx >= vocab_size:\n",
        "            continue\n",
        "        vec = embeddings_index.get(word)\n",
        "        if vec is not None:\n",
        "            embedding_matrix[idx] = vec\n",
        "            found += 1\n",
        "    print(f\"Loaded {found} / {vocab_size} embeddings.\")\n",
        "else:\n",
        "    print(\"GloVe not available; using random trainable embeddings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ndqecnPFYA3W",
      "metadata": {
        "id": "ndqecnPFYA3W"
      },
      "source": [
        "### Building the BiLSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jcZOBKynVEg4",
      "metadata": {
        "id": "jcZOBKynVEg4"
      },
      "outputs": [],
      "source": [
        "def build_bilstm(vocab_size, emb_dim=EMB_DIM, max_len=MAX_LEN, use_pretrained=True):\n",
        "    inp = layers.Input(shape=(max_len,), dtype=\"int32\")\n",
        "\n",
        "    if use_pretrained and os.path.exists(glove_txt):\n",
        "        emb = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=emb_dim,\n",
        "            weights=[embedding_matrix], input_length=max_len,\n",
        "            trainable=False, name=\"embeddings\"\n",
        "        )(inp)\n",
        "    else:\n",
        "        emb = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=emb_dim,\n",
        "            input_length=max_len, name=\"embeddings\"\n",
        "        )(inp)\n",
        "\n",
        "    x = layers.SpatialDropout1D(0.2)(emb)\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = models.Model(inp, out)\n",
        "    opt = optimizers.Adam(learning_rate=2e-3)\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3H4DarZ2YK44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "3H4DarZ2YK44",
        "outputId": "ab1a71c1-67d9-4dde-a5b1-d626c3bac72b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embeddings (\u001b[38;5;33mEmbedding\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m3,000,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m234,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embeddings (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ spatial_dropout1d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,251,009\u001b[0m (12.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,251,009</span> (12.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m251,009\u001b[0m (980.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,009</span> (980.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,000,000\u001b[0m (11.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> (11.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "bilstm = build_bilstm(vocab_size, EMB_DIM, MAX_LEN, use_pretrained=True)\n",
        "bilstm.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z8nf3ikiZIhf",
      "metadata": {
        "id": "z8nf3ikiZIhf"
      },
      "outputs": [],
      "source": [
        "# Computing class weights from the training labels\n",
        "classes = np.unique(ytr)\n",
        "class_wts = compute_class_weight(class_weight=\"balanced\", classes=classes, y=ytr)\n",
        "class_wts = {int(c): w for c, w in zip(classes, class_wts)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bH2obWLEZYHu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH2obWLEZYHu",
        "outputId": "75b5aff4-7c73-4283-b021-e21cc998049c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(1.0), 1: np.float64(1.0)}\n"
          ]
        }
      ],
      "source": [
        "print(\"Class weights:\", class_wts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wg4ZorwNZRS_",
      "metadata": {
        "id": "Wg4ZorwNZRS_"
      },
      "outputs": [],
      "source": [
        "# Early stopping + best model checkpoint\n",
        "ckpt_path = \"bilstm_best.h5\"\n",
        "cbs = [\n",
        "    callbacks.EarlyStopping(monitor=\"val_f1\", mode=\"max\", patience=3, restore_best_weights=True),\n",
        "    callbacks.ModelCheckpoint(ckpt_path, monitor=\"val_f1\", mode=\"max\", save_best_only=True, verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iAQGUpndZRQH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAQGUpndZRQH",
        "outputId": "da5af8ee-9879-419c-b2dd-5e12d8a43003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m15471/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9062 - f1_m: 0.5027 - loss: 0.2393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 20ms/step - accuracy: 0.9062 - f1_m: 0.5027 - loss: 0.2393 - val_accuracy: 0.9329 - val_f1_m: 0.5099 - val_loss: 0.1747\n",
            "Epoch 2/8\n",
            "\u001b[1m15470/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9279 - f1_m: 0.5035 - loss: 0.1888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 20ms/step - accuracy: 0.9279 - f1_m: 0.5035 - loss: 0.1888 - val_accuracy: 0.9378 - val_f1_m: 0.5067 - val_loss: 0.1627\n",
            "Epoch 3/8\n",
            "\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9317 - f1_m: 0.5041 - loss: 0.1797"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 20ms/step - accuracy: 0.9317 - f1_m: 0.5041 - loss: 0.1797 - val_accuracy: 0.9394 - val_f1_m: 0.5074 - val_loss: 0.1597\n",
            "Epoch 4/8\n",
            "\u001b[1m15470/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9333 - f1_m: 0.5045 - loss: 0.1752"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 20ms/step - accuracy: 0.9333 - f1_m: 0.5045 - loss: 0.1752 - val_accuracy: 0.9407 - val_f1_m: 0.5079 - val_loss: 0.1552\n",
            "Epoch 5/8\n",
            "\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9347 - f1_m: 0.5047 - loss: 0.1718"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 20ms/step - accuracy: 0.9347 - f1_m: 0.5047 - loss: 0.1718 - val_accuracy: 0.9412 - val_f1_m: 0.5077 - val_loss: 0.1532\n",
            "Epoch 6/8\n",
            "\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9356 - f1_m: 0.5047 - loss: 0.1695"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m15472/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 20ms/step - accuracy: 0.9356 - f1_m: 0.5047 - loss: 0.1695 - val_accuracy: 0.9423 - val_f1_m: 0.5051 - val_loss: 0.1521\n",
            "Epoch 7/8\n",
            "\u001b[1m14639/15472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m15s\u001b[0m 18ms/step - accuracy: 0.9361 - f1_m: 0.5049 - loss: 0.1679"
          ]
        }
      ],
      "source": [
        "# Custom F1 metric\n",
        "def f1_m(y_true, y_pred, thresh=0.5):\n",
        "    y_pred = tf.cast(y_pred > thresh, tf.float32)\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    tp = tf.reduce_sum(tf.cast(y_true*y_pred, tf.float32))\n",
        "    fp = tf.reduce_sum(tf.cast((1-y_true)*y_pred, tf.float32))\n",
        "    fn = tf.reduce_sum(tf.cast(y_true*(1-y_pred), tf.float32))\n",
        "    precision = tp / (tp + fp + 1e-12)\n",
        "    recall    = tp / (tp + fn + 1e-12)\n",
        "    return 2*precision*recall/(precision+recall+1e-12)\n",
        "\n",
        "bilstm.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-3),\n",
        "    metrics=[\"accuracy\", f1_m]\n",
        ")\n",
        "\n",
        "history = bilstm.fit(\n",
        "    Xtr_pad, ytr,\n",
        "    validation_data=(Xva_pad, yva),\n",
        "    epochs=8,\n",
        "    batch_size=128,\n",
        "    class_weight=class_wts,\n",
        "    callbacks=cbs,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jYw3_E4jZRKo",
      "metadata": {
        "id": "jYw3_E4jZRKo"
      },
      "outputs": [],
      "source": [
        "def plot_history(h, metrics=(\"accuracy\",\"f1_m\")):\n",
        "    for m in metrics:\n",
        "        plt.figure(figsize=(5,3.5))\n",
        "        plt.plot(h.history[m], label=f\"train_{m}\")\n",
        "        plt.plot(h.history[f\"val_{m}\"], label=f\"val_{m}\")\n",
        "        plt.title(f\"Training history — {m}\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(m)\n",
        "        plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "plot_history(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rbRV1YdLZRID",
      "metadata": {
        "id": "rbRV1YdLZRID"
      },
      "outputs": [],
      "source": [
        "# Probabilities\n",
        "val_proba_bilstm = bilstm.predict(Xva_pad, batch_size=512).ravel()\n",
        "test_proba_bilstm = bilstm.predict(Xte_pad, batch_size=512).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feSa_7PodI8Z",
      "metadata": {
        "id": "feSa_7PodI8Z"
      },
      "outputs": [],
      "source": [
        "# Default 0.5 threshold\n",
        "val_pred_bilstm  = (val_proba_bilstm >= 0.5).astype(int)\n",
        "test_pred_bilstm = (test_proba_bilstm >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-1QEh3yudLEG",
      "metadata": {
        "id": "-1QEh3yudLEG"
      },
      "outputs": [],
      "source": [
        "# Reports\n",
        "print(\"BiLSTM — Validation\")\n",
        "print(classification_report(yva, val_pred_bilstm, target_names=[\"Non-Depressed\",\"Depressed\"]))\n",
        "print(\"ROC-AUC (val):\", roc_auc_score(yva, val_proba_bilstm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ezl4qts1dLBz",
      "metadata": {
        "id": "ezl4qts1dLBz"
      },
      "outputs": [],
      "source": [
        "print(\"\\nBiLSTM — Test\")\n",
        "print(classification_report(yte, test_pred_bilstm, target_names=[\"Non-Depressed\",\"Depressed\"]))\n",
        "print(\"ROC-AUC (test):\", roc_auc_score(yte, test_proba_bilstm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n_U-A_OadK_r",
      "metadata": {
        "id": "n_U-A_OadK_r"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    yte, test_pred_bilstm, display_labels=[\"Non-Depressed\",\"Depressed\"],\n",
        "    cmap=\"magma\", values_format=\"d\"\n",
        ")\n",
        "plt.title(\"BiLSTM — Confusion Matrix\")\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BWTApqhmdK9V",
      "metadata": {
        "id": "BWTApqhmdK9V"
      },
      "outputs": [],
      "source": [
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(yte, test_proba_bilstm)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(yte, test_proba_bilstm):.3f}\")\n",
        "plt.plot([0,1],[0,1],'k--'); plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"BiLSTM — ROC\"); plt.legend(); plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nL5v8mR9dK6O",
      "metadata": {
        "id": "nL5v8mR9dK6O"
      },
      "outputs": [],
      "source": [
        "# Precision–Recall\n",
        "prec, rec, _ = precision_recall_curve(yte, test_proba_bilstm)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(rec, prec, label=f\"AP = {average_precision_score(yte, test_proba_bilstm):.3f}\")\n",
        "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(\"BiLSTM — Precision–Recall\"); plt.legend(); plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-RXvjaGidK3l",
      "metadata": {
        "id": "-RXvjaGidK3l"
      },
      "outputs": [],
      "source": [
        "def best_threshold_by_f1(y_true, scores):\n",
        "    prec, rec, thr = precision_recall_curve(y_true, scores)\n",
        "    thr = np.append(thr, 1.0)\n",
        "    f1s = 2*(prec*rec)/(prec+rec+1e-12)\n",
        "    i = np.argmax(f1s)\n",
        "    return float(thr[i]), {\"precision\": float(prec[i]), \"recall\": float(rec[i]), \"f1\": float(f1s[i])}\n",
        "\n",
        "thr_bilstm, stats_bilstm = best_threshold_by_f1(yva, val_proba_bilstm)\n",
        "print(\"Best BiLSTM threshold on validation:\", round(thr_bilstm,3), stats_bilstm)\n",
        "\n",
        "test_pred_bilstm_tuned = (test_proba_bilstm >= thr_bilstm).astype(int)\n",
        "print(\"\\nBiLSTM (Test) with tuned threshold:\")\n",
        "print(classification_report(yte, test_pred_bilstm_tuned, target_names=[\"Non-Depressed\",\"Depressed\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7qIz6ON-dK1A",
      "metadata": {
        "id": "7qIz6ON-dK1A"
      },
      "outputs": [],
      "source": [
        "bilstm.save(\"bilstm_model.h5\")\n",
        "print(\"Saved bilstm_model.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3DqIbsjGmbqG",
      "metadata": {
        "id": "3DqIbsjGmbqG"
      },
      "source": [
        "## Model comparison table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fNPJ_zuvk0MW",
      "metadata": {
        "id": "fNPJ_zuvk0MW"
      },
      "outputs": [],
      "source": [
        "rows = []\n",
        "\n",
        "# LR\n",
        "if 'test_proba_lr' in globals():\n",
        "    rows.append({\"Model\":\"LogReg\", \"F1_test\": f1_score(y_test, (test_proba_lr>=0.5)),\n",
        "                 \"ROC_AUC_test\": roc_auc_score(y_test, test_proba_lr)})\n",
        "\n",
        "# SVM\n",
        "if 'test_scores_svm' in globals():\n",
        "    rows.append({\"Model\":\"Linear SVM\", \"F1_test\": f1_score(y_test, (test_scores_svm>=0)),\n",
        "                 \"ROC_AUC_test\": roc_auc_score(y_test, test_scores_svm)})\n",
        "\n",
        "# BiLSTM\n",
        "rows.append({\"Model\":\"BiLSTM\", \"F1_test\": f1_score(yte, test_pred_bilstm),\n",
        "             \"ROC_AUC_test\": roc_auc_score(yte, test_proba_bilstm)})\n",
        "\n",
        "pd.DataFrame(rows).sort_values(\"F1_test\", ascending=False).round(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kxkbOjAZIb_Q",
      "metadata": {
        "id": "kxkbOjAZIb_Q"
      },
      "source": [
        "#### Small implimentation of SBERT (Sentence-BERT) on which future work that can be done"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}